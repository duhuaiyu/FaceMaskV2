{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, models, datasets\n",
    "import time\n",
    "import copy"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### User transfer learning to build new classification model\n",
    "# refer from https://www.udemy.com/course/pytorch-best/learn/lecture/17161282?start=540#overview"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "data_dir = '/home/duhuaiyu/Downloads/facemaskdata/temp'\n",
    "train_dir = data_dir + '/train'\n",
    "valid_dir = data_dir + '/valid'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# define transforms to auto process images"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(32),\n",
    "        transforms.RandomApply(\n",
    "            torch.nn.ModuleList([transforms.GaussianBlur(kernel_size=(5,5))]), p = 0.2),\n",
    "        transforms.RandomRotation(5),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.1, saturation=0.1, hue=0.1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])#\n",
    "    ]),\n",
    "    'valid':\n",
    "        transforms.Compose([\n",
    "        transforms.Resize(32),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load training data and test data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "batch_size = 500\n",
    "\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'valid']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True) for x in ['train', 'valid']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'valid']}\n",
    "class_names = image_datasets['train'].classes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# frozen all layers if needed\n",
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# define a Identity layer used in reconstruct vgg16 model\n",
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "# reconstruct vgg16 model, fix input size to 32 by 32\n",
    "def initialize_model_first_train(num_classes, feature_extract, use_pretrained=True):\n",
    "\n",
    "    model_ft = models.vgg16(pretrained=use_pretrained)\n",
    "    set_parameter_requires_grad(model_ft, feature_extract)\n",
    "    # replace avgpool with Identity layers since input size fixed to 32 by 32\n",
    "    model_ft.avgpool = Identity()\n",
    "    # redefine classifer layers\n",
    "    model_ft.classifier= nn.Sequential(\n",
    "            nn.Linear(512, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, num_classes),\n",
    "    )\n",
    "    return model_ft"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!  Training on GPU ...\n"
     ]
    }
   ],
   "source": [
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available.  Training on CPU ...')\n",
    "else:\n",
    "    print('CUDA is available!  Training on GPU ...')\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): Identity()\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=4, bias=True)\n",
      "  )\n",
      ")\n",
      "Params to learn:\n",
      "\t classifier.0.weight\n",
      "\t classifier.0.bias\n",
      "\t classifier.3.weight\n",
      "\t classifier.3.bias\n",
      "\t classifier.6.weight\n",
      "\t classifier.6.bias\n"
     ]
    }
   ],
   "source": [
    "# frozen all feature extract layers\n",
    "feature_extract = True\n",
    "model_ft = initialize_model_first_train(4, feature_extract, use_pretrained=True)\n",
    "\n",
    "# use GPU computate\n",
    "model_ft = model_ft.to(device)\n",
    "#print(model_ft)\n",
    "# save model file name\n",
    "filename='checkpoint_first_round.pth'\n",
    "params_to_update = model_ft.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=50, is_inception=False, filename=\"checkpoint.pth\"):\n",
    "    since = time.time()\n",
    "    best_acc = 0\n",
    "    model.to(device)\n",
    "\n",
    "    val_acc_history = []\n",
    "    train_acc_history = []\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    LRs = [optimizer.param_groups[0]['lr']]\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # train and validation\n",
    "        for phase in ['train', 'valid']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # train\n",
    "            else:\n",
    "                model.eval()  # validation\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                #print(phase,inputs.shape,labels.shape)\n",
    "\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # clear gradient\n",
    "                optimizer.zero_grad()\n",
    "                # only update gradient during training phase\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    #print(inputs.shape)\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # update gradient\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # compute loss\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            time_elapsed = time.time() - since\n",
    "            print('Time elapsed {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # save the model with best accuracy\n",
    "            if phase == 'valid' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                state = {\n",
    "                    'state_dict': model.state_dict(),\n",
    "                    'best_acc': best_acc,\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                }\n",
    "                torch.save(state, filename)\n",
    "            if phase == 'valid':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "                valid_losses.append(epoch_loss)\n",
    "                scheduler.step()\n",
    "            if phase == 'train':\n",
    "                train_acc_history.append(epoch_acc)\n",
    "                train_losses.append(epoch_loss)\n",
    "\n",
    "        print('Optimizer learning rate : {:.7f}'.format(optimizer.param_groups[0]['lr']))\n",
    "        LRs.append(optimizer.param_groups[0]['lr'])\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load the best accuracy model\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history, train_acc_history, valid_losses, train_losses, LRs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'params_to_update' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-11-942b20e0d0d7>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0moptimizer_ft\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0moptim\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mSGD\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mparams_to_update\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlr\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0.001\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmomentum\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0.9\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;31m# optimizer_ft = optim.Adam(params_to_update, lr=1e-4)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0mscheduler\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0moptim\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlr_scheduler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mStepLR\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moptimizer_ft\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstep_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m7\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgamma\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0.5\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;31m#学习率每7个epoch衰减成原来的1/10\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;31m#最后一层已经LogSoftmax()了，所以不能nn.CrossEntropyLoss()来计算了，nn.CrossEntropyLoss()相当于logSoftmax()和nn.NLLLoss()整合\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;31m# criterion = nn.NLLLoss()\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'params_to_update' is not defined"
     ]
    }
   ],
   "source": [
    "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.5)\n",
    "criterion = nn.CrossEntropyLoss()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train the model the first time"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/49\n",
      "----------\n",
      "Time elapsed 0m 36s\n",
      "train Loss: 0.7869 Acc: 0.6987\n",
      "Time elapsed 0m 38s\n",
      "valid Loss: 0.4660 Acc: 0.8668\n",
      "Optimizer learning rate : 0.0010000\n",
      "\n",
      "Epoch 1/49\n",
      "----------\n",
      "Time elapsed 1m 15s\n",
      "train Loss: 0.5387 Acc: 0.8215\n",
      "Time elapsed 1m 17s\n",
      "valid Loss: 0.3445 Acc: 0.8944\n",
      "Optimizer learning rate : 0.0010000\n",
      "\n",
      "Epoch 2/49\n",
      "----------\n",
      "Time elapsed 1m 53s\n",
      "train Loss: 0.4722 Acc: 0.8428\n",
      "Time elapsed 1m 55s\n",
      "valid Loss: 0.2842 Acc: 0.9131\n",
      "Optimizer learning rate : 0.0010000\n",
      "\n",
      "Epoch 3/49\n",
      "----------\n",
      "Time elapsed 2m 31s\n",
      "train Loss: 0.4424 Acc: 0.8518\n",
      "Time elapsed 2m 34s\n",
      "valid Loss: 0.2620 Acc: 0.9184\n",
      "Optimizer learning rate : 0.0010000\n",
      "\n",
      "Epoch 4/49\n",
      "----------\n",
      "Time elapsed 3m 10s\n",
      "train Loss: 0.4208 Acc: 0.8588\n",
      "Time elapsed 3m 12s\n",
      "valid Loss: 0.2404 Acc: 0.9258\n",
      "Optimizer learning rate : 0.0010000\n",
      "\n",
      "Epoch 5/49\n",
      "----------\n",
      "Time elapsed 3m 48s\n",
      "train Loss: 0.4056 Acc: 0.8630\n",
      "Time elapsed 3m 51s\n",
      "valid Loss: 0.2353 Acc: 0.9247\n",
      "Optimizer learning rate : 0.0010000\n",
      "\n",
      "Epoch 6/49\n",
      "----------\n",
      "Time elapsed 4m 27s\n",
      "train Loss: 0.3927 Acc: 0.8648\n",
      "Time elapsed 4m 29s\n",
      "valid Loss: 0.2298 Acc: 0.9261\n",
      "Optimizer learning rate : 0.0005000\n",
      "\n",
      "Epoch 7/49\n",
      "----------\n",
      "Time elapsed 5m 5s\n",
      "train Loss: 0.3852 Acc: 0.8687\n",
      "Time elapsed 5m 7s\n",
      "valid Loss: 0.2133 Acc: 0.9311\n",
      "Optimizer learning rate : 0.0005000\n",
      "\n",
      "Epoch 8/49\n",
      "----------\n",
      "Time elapsed 5m 44s\n",
      "train Loss: 0.3827 Acc: 0.8689\n",
      "Time elapsed 5m 46s\n",
      "valid Loss: 0.2266 Acc: 0.9267\n",
      "Optimizer learning rate : 0.0005000\n",
      "\n",
      "Epoch 9/49\n",
      "----------\n",
      "Time elapsed 6m 22s\n",
      "train Loss: 0.3797 Acc: 0.8718\n",
      "Time elapsed 6m 24s\n",
      "valid Loss: 0.2155 Acc: 0.9307\n",
      "Optimizer learning rate : 0.0005000\n",
      "\n",
      "Epoch 10/49\n",
      "----------\n",
      "Time elapsed 7m 0s\n",
      "train Loss: 0.3730 Acc: 0.8731\n",
      "Time elapsed 7m 2s\n",
      "valid Loss: 0.2134 Acc: 0.9305\n",
      "Optimizer learning rate : 0.0005000\n",
      "\n",
      "Epoch 11/49\n",
      "----------\n",
      "Time elapsed 7m 38s\n",
      "train Loss: 0.3701 Acc: 0.8733\n",
      "Time elapsed 7m 40s\n",
      "valid Loss: 0.2041 Acc: 0.9347\n",
      "Optimizer learning rate : 0.0005000\n",
      "\n",
      "Epoch 12/49\n",
      "----------\n",
      "Time elapsed 8m 17s\n",
      "train Loss: 0.3679 Acc: 0.8745\n",
      "Time elapsed 8m 19s\n",
      "valid Loss: 0.2077 Acc: 0.9328\n",
      "Optimizer learning rate : 0.0005000\n",
      "\n",
      "Epoch 13/49\n",
      "----------\n",
      "Time elapsed 8m 55s\n",
      "train Loss: 0.3635 Acc: 0.8763\n",
      "Time elapsed 8m 57s\n",
      "valid Loss: 0.2039 Acc: 0.9341\n",
      "Optimizer learning rate : 0.0002500\n",
      "\n",
      "Epoch 14/49\n",
      "----------\n",
      "Time elapsed 9m 33s\n",
      "train Loss: 0.3648 Acc: 0.8736\n",
      "Time elapsed 9m 35s\n",
      "valid Loss: 0.1959 Acc: 0.9368\n",
      "Optimizer learning rate : 0.0002500\n",
      "\n",
      "Epoch 15/49\n",
      "----------\n",
      "Time elapsed 10m 12s\n",
      "train Loss: 0.3619 Acc: 0.8764\n",
      "Time elapsed 10m 14s\n",
      "valid Loss: 0.2033 Acc: 0.9352\n",
      "Optimizer learning rate : 0.0002500\n",
      "\n",
      "Epoch 16/49\n",
      "----------\n",
      "Time elapsed 10m 50s\n",
      "train Loss: 0.3575 Acc: 0.8755\n",
      "Time elapsed 10m 52s\n",
      "valid Loss: 0.1960 Acc: 0.9368\n",
      "Optimizer learning rate : 0.0002500\n",
      "\n",
      "Epoch 17/49\n",
      "----------\n",
      "Time elapsed 11m 28s\n",
      "train Loss: 0.3552 Acc: 0.8793\n",
      "Time elapsed 11m 30s\n",
      "valid Loss: 0.1958 Acc: 0.9367\n",
      "Optimizer learning rate : 0.0002500\n",
      "\n",
      "Epoch 18/49\n",
      "----------\n",
      "Time elapsed 12m 6s\n",
      "train Loss: 0.3570 Acc: 0.8751\n",
      "Time elapsed 12m 8s\n",
      "valid Loss: 0.1930 Acc: 0.9376\n",
      "Optimizer learning rate : 0.0002500\n",
      "\n",
      "Epoch 19/49\n",
      "----------\n",
      "Time elapsed 12m 45s\n",
      "train Loss: 0.3535 Acc: 0.8790\n",
      "Time elapsed 12m 47s\n",
      "valid Loss: 0.2021 Acc: 0.9347\n",
      "Optimizer learning rate : 0.0002500\n",
      "\n",
      "Epoch 20/49\n",
      "----------\n",
      "Time elapsed 13m 23s\n",
      "train Loss: 0.3560 Acc: 0.8755\n",
      "Time elapsed 13m 25s\n",
      "valid Loss: 0.1982 Acc: 0.9358\n",
      "Optimizer learning rate : 0.0001250\n",
      "\n",
      "Epoch 21/49\n",
      "----------\n",
      "Time elapsed 14m 1s\n",
      "train Loss: 0.3554 Acc: 0.8771\n",
      "Time elapsed 14m 3s\n",
      "valid Loss: 0.1928 Acc: 0.9376\n",
      "Optimizer learning rate : 0.0001250\n",
      "\n",
      "Epoch 22/49\n",
      "----------\n",
      "Time elapsed 14m 39s\n",
      "train Loss: 0.3496 Acc: 0.8788\n",
      "Time elapsed 14m 42s\n",
      "valid Loss: 0.1924 Acc: 0.9376\n",
      "Optimizer learning rate : 0.0001250\n",
      "\n",
      "Epoch 23/49\n",
      "----------\n",
      "Time elapsed 15m 18s\n",
      "train Loss: 0.3548 Acc: 0.8778\n",
      "Time elapsed 15m 20s\n",
      "valid Loss: 0.1964 Acc: 0.9359\n",
      "Optimizer learning rate : 0.0001250\n",
      "\n",
      "Epoch 24/49\n",
      "----------\n",
      "Time elapsed 15m 56s\n",
      "train Loss: 0.3538 Acc: 0.8795\n",
      "Time elapsed 15m 58s\n",
      "valid Loss: 0.1943 Acc: 0.9368\n",
      "Optimizer learning rate : 0.0001250\n",
      "\n",
      "Epoch 25/49\n",
      "----------\n",
      "Time elapsed 16m 34s\n",
      "train Loss: 0.3513 Acc: 0.8784\n",
      "Time elapsed 16m 37s\n",
      "valid Loss: 0.1935 Acc: 0.9373\n",
      "Optimizer learning rate : 0.0001250\n",
      "\n",
      "Epoch 26/49\n",
      "----------\n",
      "Time elapsed 17m 13s\n",
      "train Loss: 0.3498 Acc: 0.8781\n",
      "Time elapsed 17m 15s\n",
      "valid Loss: 0.1936 Acc: 0.9373\n",
      "Optimizer learning rate : 0.0001250\n",
      "\n",
      "Epoch 27/49\n",
      "----------\n",
      "Time elapsed 17m 51s\n",
      "train Loss: 0.3523 Acc: 0.8782\n",
      "Time elapsed 17m 53s\n",
      "valid Loss: 0.1902 Acc: 0.9380\n",
      "Optimizer learning rate : 0.0000625\n",
      "\n",
      "Epoch 28/49\n",
      "----------\n",
      "Time elapsed 18m 29s\n",
      "train Loss: 0.3525 Acc: 0.8782\n",
      "Time elapsed 18m 32s\n",
      "valid Loss: 0.1925 Acc: 0.9379\n",
      "Optimizer learning rate : 0.0000625\n",
      "\n",
      "Epoch 29/49\n",
      "----------\n",
      "Time elapsed 19m 7s\n",
      "train Loss: 0.3518 Acc: 0.8783\n",
      "Time elapsed 19m 10s\n",
      "valid Loss: 0.1901 Acc: 0.9382\n",
      "Optimizer learning rate : 0.0000625\n",
      "\n",
      "Epoch 30/49\n",
      "----------\n",
      "Time elapsed 19m 46s\n",
      "train Loss: 0.3490 Acc: 0.8784\n",
      "Time elapsed 19m 48s\n",
      "valid Loss: 0.1906 Acc: 0.9380\n",
      "Optimizer learning rate : 0.0000625\n",
      "\n",
      "Epoch 31/49\n",
      "----------\n",
      "Time elapsed 20m 24s\n",
      "train Loss: 0.3473 Acc: 0.8811\n",
      "Time elapsed 20m 26s\n",
      "valid Loss: 0.1924 Acc: 0.9379\n",
      "Optimizer learning rate : 0.0000625\n",
      "\n",
      "Epoch 32/49\n",
      "----------\n",
      "Time elapsed 21m 2s\n",
      "train Loss: 0.3484 Acc: 0.8786\n",
      "Time elapsed 21m 4s\n",
      "valid Loss: 0.1923 Acc: 0.9377\n",
      "Optimizer learning rate : 0.0000625\n",
      "\n",
      "Epoch 33/49\n",
      "----------\n",
      "Time elapsed 21m 39s\n",
      "train Loss: 0.3472 Acc: 0.8791\n",
      "Time elapsed 21m 42s\n",
      "valid Loss: 0.1927 Acc: 0.9379\n",
      "Optimizer learning rate : 0.0000625\n",
      "\n",
      "Epoch 34/49\n",
      "----------\n",
      "Time elapsed 22m 17s\n",
      "train Loss: 0.3494 Acc: 0.8797\n",
      "Time elapsed 22m 19s\n",
      "valid Loss: 0.1897 Acc: 0.9386\n",
      "Optimizer learning rate : 0.0000313\n",
      "\n",
      "Epoch 35/49\n",
      "----------\n",
      "Time elapsed 22m 56s\n",
      "train Loss: 0.3461 Acc: 0.8802\n",
      "Time elapsed 22m 58s\n",
      "valid Loss: 0.1917 Acc: 0.9382\n",
      "Optimizer learning rate : 0.0000313\n",
      "\n",
      "Epoch 36/49\n",
      "----------\n",
      "Time elapsed 23m 33s\n",
      "train Loss: 0.3491 Acc: 0.8783\n",
      "Time elapsed 23m 36s\n",
      "valid Loss: 0.1913 Acc: 0.9382\n",
      "Optimizer learning rate : 0.0000313\n",
      "\n",
      "Epoch 37/49\n",
      "----------\n",
      "Time elapsed 24m 11s\n",
      "train Loss: 0.3452 Acc: 0.8809\n",
      "Time elapsed 24m 13s\n",
      "valid Loss: 0.1910 Acc: 0.9383\n",
      "Optimizer learning rate : 0.0000313\n",
      "\n",
      "Epoch 38/49\n",
      "----------\n",
      "Time elapsed 24m 49s\n",
      "train Loss: 0.3443 Acc: 0.8806\n",
      "Time elapsed 24m 51s\n",
      "valid Loss: 0.1912 Acc: 0.9383\n",
      "Optimizer learning rate : 0.0000313\n",
      "\n",
      "Epoch 39/49\n",
      "----------\n",
      "Time elapsed 25m 27s\n",
      "train Loss: 0.3467 Acc: 0.8807\n",
      "Time elapsed 25m 29s\n",
      "valid Loss: 0.1909 Acc: 0.9383\n",
      "Optimizer learning rate : 0.0000313\n",
      "\n",
      "Epoch 40/49\n",
      "----------\n",
      "Time elapsed 26m 4s\n",
      "train Loss: 0.3497 Acc: 0.8793\n",
      "Time elapsed 26m 7s\n",
      "valid Loss: 0.1900 Acc: 0.9386\n",
      "Optimizer learning rate : 0.0000313\n",
      "\n",
      "Epoch 41/49\n",
      "----------\n",
      "Time elapsed 26m 42s\n",
      "train Loss: 0.3468 Acc: 0.8791\n",
      "Time elapsed 26m 44s\n",
      "valid Loss: 0.1900 Acc: 0.9388\n",
      "Optimizer learning rate : 0.0000156\n",
      "\n",
      "Epoch 42/49\n",
      "----------\n",
      "Time elapsed 27m 21s\n",
      "train Loss: 0.3497 Acc: 0.8784\n",
      "Time elapsed 27m 23s\n",
      "valid Loss: 0.1901 Acc: 0.9386\n",
      "Optimizer learning rate : 0.0000156\n",
      "\n",
      "Epoch 43/49\n",
      "----------\n",
      "Time elapsed 27m 58s\n",
      "train Loss: 0.3481 Acc: 0.8782\n",
      "Time elapsed 28m 1s\n",
      "valid Loss: 0.1906 Acc: 0.9385\n",
      "Optimizer learning rate : 0.0000156\n",
      "\n",
      "Epoch 44/49\n",
      "----------\n",
      "Time elapsed 28m 36s\n",
      "train Loss: 0.3450 Acc: 0.8812\n",
      "Time elapsed 28m 38s\n",
      "valid Loss: 0.1901 Acc: 0.9386\n",
      "Optimizer learning rate : 0.0000156\n",
      "\n",
      "Epoch 45/49\n",
      "----------\n",
      "Time elapsed 29m 14s\n",
      "train Loss: 0.3459 Acc: 0.8816\n",
      "Time elapsed 29m 16s\n",
      "valid Loss: 0.1906 Acc: 0.9385\n",
      "Optimizer learning rate : 0.0000156\n",
      "\n",
      "Epoch 46/49\n",
      "----------\n",
      "Time elapsed 29m 52s\n",
      "train Loss: 0.3455 Acc: 0.8819\n",
      "Time elapsed 29m 54s\n",
      "valid Loss: 0.1910 Acc: 0.9385\n",
      "Optimizer learning rate : 0.0000156\n",
      "\n",
      "Epoch 47/49\n",
      "----------\n",
      "Time elapsed 30m 29s\n",
      "train Loss: 0.3473 Acc: 0.8815\n",
      "Time elapsed 30m 31s\n",
      "valid Loss: 0.1906 Acc: 0.9386\n",
      "Optimizer learning rate : 0.0000156\n",
      "\n",
      "Epoch 48/49\n",
      "----------\n",
      "Time elapsed 31m 7s\n",
      "train Loss: 0.3450 Acc: 0.8804\n",
      "Time elapsed 31m 9s\n",
      "valid Loss: 0.1900 Acc: 0.9388\n",
      "Optimizer learning rate : 0.0000078\n",
      "\n",
      "Epoch 49/49\n",
      "----------\n",
      "Time elapsed 31m 45s\n",
      "train Loss: 0.3478 Acc: 0.8794\n",
      "Time elapsed 31m 47s\n",
      "valid Loss: 0.1901 Acc: 0.9389\n",
      "Optimizer learning rate : 0.0000078\n",
      "\n",
      "Training complete in 31m 47s\n",
      "Best val Acc: 0.938910\n"
     ]
    }
   ],
   "source": [
    "model_ft, val_acc_history, train_acc_history, valid_losses, train_losses, LRs  = train_model(model_ft, dataloaders, criterion, optimizer_ft, num_epochs=50, is_inception=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### the Following cells used to enhance the trained model,\n",
    "#load model from file and use new data to train it more epoch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t features.19.weight\n",
      "\t features.19.bias\n",
      "\t features.21.weight\n",
      "\t features.21.bias\n",
      "\t features.24.weight\n",
      "\t features.24.bias\n",
      "\t features.26.weight\n",
      "\t features.26.bias\n",
      "\t features.28.weight\n",
      "\t features.28.bias\n",
      "\t classifier.0.weight\n",
      "\t classifier.0.bias\n",
      "\t classifier.3.weight\n",
      "\t classifier.3.bias\n",
      "\t classifier.6.weight\n",
      "\t classifier.6.bias\n"
     ]
    }
   ],
   "source": [
    "def fix_layer_number(model, layer_number):\n",
    "    for idx,param in enumerate(model.parameters()):\n",
    "        if idx > layer_number:\n",
    "            break;\n",
    "        param.requires_grad = False\n",
    "def loadModel(filePath, fixed_layer_num):\n",
    "    # 选择合适的模型，不同模型的初始化方法稍微有点区别\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = models.vgg16(pretrained=False)\n",
    "    model.avgpool = Identity()\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Linear(512, 4096),\n",
    "        nn.ReLU(True),\n",
    "        nn.Dropout(),\n",
    "        nn.Linear(4096, 4096),\n",
    "        nn.ReLU(True),\n",
    "        nn.Dropout(),\n",
    "        nn.Linear(4096, 4),\n",
    "    )\n",
    "    checkpoint = torch.load(filePath)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    fix_layer_number(model, fixed_layer_num)\n",
    "    model = model.to(device)\n",
    "    return model\n",
    "# load the model trained previous, frozen first 15th layers\n",
    "model_continue = loadModel(\"checkpoint_31_12.pth\",15)\n",
    "params_to_update = model_continue.parameters()\n",
    "print(\"Params to learn:\")\n",
    "\n",
    "params_to_update = []\n",
    "for name,param in model_continue.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "        print(\"\\t\",name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/29\n",
      "----------\n",
      "Time elapsed 1m 33s\n",
      "train Loss: 0.1876 Acc: 0.9310\n",
      "Time elapsed 1m 38s\n",
      "valid Loss: 0.1190 Acc: 0.9588\n",
      "Optimizer learning rate : 0.0010000\n",
      "\n",
      "Epoch 1/29\n",
      "----------\n",
      "Time elapsed 2m 56s\n",
      "train Loss: 0.1586 Acc: 0.9408\n",
      "Time elapsed 3m 1s\n",
      "valid Loss: 0.0970 Acc: 0.9655\n",
      "Optimizer learning rate : 0.0010000\n",
      "\n",
      "Epoch 2/29\n",
      "----------\n",
      "Time elapsed 4m 17s\n",
      "train Loss: 0.1450 Acc: 0.9468\n",
      "Time elapsed 4m 21s\n",
      "valid Loss: 0.1036 Acc: 0.9648\n",
      "Optimizer learning rate : 0.0010000\n",
      "\n",
      "Epoch 3/29\n",
      "----------\n",
      "Time elapsed 5m 36s\n",
      "train Loss: 0.1380 Acc: 0.9499\n",
      "Time elapsed 5m 40s\n",
      "valid Loss: 0.1100 Acc: 0.9615\n",
      "Optimizer learning rate : 0.0010000\n",
      "\n",
      "Epoch 4/29\n",
      "----------\n",
      "Time elapsed 6m 55s\n",
      "train Loss: 0.1288 Acc: 0.9535\n",
      "Time elapsed 6m 59s\n",
      "valid Loss: 0.0822 Acc: 0.9728\n",
      "Optimizer learning rate : 0.0010000\n",
      "\n",
      "Epoch 5/29\n",
      "----------\n",
      "Time elapsed 8m 14s\n",
      "train Loss: 0.1222 Acc: 0.9551\n",
      "Time elapsed 8m 18s\n",
      "valid Loss: 0.1118 Acc: 0.9616\n",
      "Optimizer learning rate : 0.0010000\n",
      "\n",
      "Epoch 6/29\n",
      "----------\n",
      "Time elapsed 9m 32s\n",
      "train Loss: 0.1169 Acc: 0.9582\n",
      "Time elapsed 9m 36s\n",
      "valid Loss: 0.0915 Acc: 0.9691\n",
      "Optimizer learning rate : 0.0005000\n",
      "\n",
      "Epoch 7/29\n",
      "----------\n",
      "Time elapsed 10m 51s\n",
      "train Loss: 0.1092 Acc: 0.9601\n",
      "Time elapsed 10m 55s\n",
      "valid Loss: 0.1032 Acc: 0.9649\n",
      "Optimizer learning rate : 0.0005000\n",
      "\n",
      "Epoch 8/29\n",
      "----------\n",
      "Time elapsed 12m 10s\n",
      "train Loss: 0.1067 Acc: 0.9617\n",
      "Time elapsed 12m 14s\n",
      "valid Loss: 0.0891 Acc: 0.9699\n",
      "Optimizer learning rate : 0.0005000\n",
      "\n",
      "Epoch 9/29\n",
      "----------\n",
      "Time elapsed 13m 29s\n",
      "train Loss: 0.1036 Acc: 0.9622\n",
      "Time elapsed 13m 33s\n",
      "valid Loss: 0.0819 Acc: 0.9717\n",
      "Optimizer learning rate : 0.0005000\n",
      "\n",
      "Epoch 10/29\n",
      "----------\n",
      "Time elapsed 14m 50s\n",
      "train Loss: 0.1011 Acc: 0.9636\n",
      "Time elapsed 14m 54s\n",
      "valid Loss: 0.0850 Acc: 0.9712\n",
      "Optimizer learning rate : 0.0005000\n",
      "\n",
      "Epoch 11/29\n",
      "----------\n",
      "Time elapsed 16m 13s\n",
      "train Loss: 0.0988 Acc: 0.9639\n",
      "Time elapsed 16m 17s\n",
      "valid Loss: 0.0799 Acc: 0.9736\n",
      "Optimizer learning rate : 0.0005000\n",
      "\n",
      "Epoch 12/29\n",
      "----------\n",
      "Time elapsed 17m 36s\n",
      "train Loss: 0.0980 Acc: 0.9648\n",
      "Time elapsed 17m 40s\n",
      "valid Loss: 0.0803 Acc: 0.9729\n",
      "Optimizer learning rate : 0.0005000\n",
      "\n",
      "Epoch 13/29\n",
      "----------\n",
      "Time elapsed 18m 57s\n",
      "train Loss: 0.0961 Acc: 0.9655\n",
      "Time elapsed 19m 1s\n",
      "valid Loss: 0.0946 Acc: 0.9679\n",
      "Optimizer learning rate : 0.0002500\n",
      "\n",
      "Epoch 14/29\n",
      "----------\n",
      "Time elapsed 20m 18s\n",
      "train Loss: 0.0931 Acc: 0.9667\n",
      "Time elapsed 20m 22s\n",
      "valid Loss: 0.0845 Acc: 0.9713\n",
      "Optimizer learning rate : 0.0002500\n",
      "\n",
      "Epoch 15/29\n",
      "----------\n",
      "Time elapsed 21m 39s\n",
      "train Loss: 0.0919 Acc: 0.9672\n",
      "Time elapsed 21m 43s\n",
      "valid Loss: 0.0784 Acc: 0.9741\n",
      "Optimizer learning rate : 0.0002500\n",
      "\n",
      "Epoch 16/29\n",
      "----------\n",
      "Time elapsed 23m 0s\n",
      "train Loss: 0.0910 Acc: 0.9673\n",
      "Time elapsed 23m 4s\n",
      "valid Loss: 0.0819 Acc: 0.9728\n",
      "Optimizer learning rate : 0.0002500\n",
      "\n",
      "Epoch 17/29\n",
      "----------\n",
      "Time elapsed 24m 21s\n",
      "train Loss: 0.0910 Acc: 0.9669\n",
      "Time elapsed 24m 25s\n",
      "valid Loss: 0.0861 Acc: 0.9706\n",
      "Optimizer learning rate : 0.0002500\n",
      "\n",
      "Epoch 18/29\n",
      "----------\n",
      "Time elapsed 25m 44s\n",
      "train Loss: 0.0898 Acc: 0.9688\n",
      "Time elapsed 25m 48s\n",
      "valid Loss: 0.0744 Acc: 0.9753\n",
      "Optimizer learning rate : 0.0002500\n",
      "\n",
      "Epoch 19/29\n",
      "----------\n",
      "Time elapsed 27m 6s\n",
      "train Loss: 0.0887 Acc: 0.9683\n",
      "Time elapsed 27m 10s\n",
      "valid Loss: 0.0734 Acc: 0.9763\n",
      "Optimizer learning rate : 0.0002500\n",
      "\n",
      "Epoch 20/29\n",
      "----------\n",
      "Time elapsed 28m 29s\n",
      "train Loss: 0.0868 Acc: 0.9686\n",
      "Time elapsed 28m 34s\n",
      "valid Loss: 0.0724 Acc: 0.9756\n",
      "Optimizer learning rate : 0.0001250\n",
      "\n",
      "Epoch 21/29\n",
      "----------\n",
      "Time elapsed 29m 53s\n",
      "train Loss: 0.0850 Acc: 0.9687\n",
      "Time elapsed 29m 57s\n",
      "valid Loss: 0.0822 Acc: 0.9716\n",
      "Optimizer learning rate : 0.0001250\n",
      "\n",
      "Epoch 22/29\n",
      "----------\n",
      "Time elapsed 31m 11s\n",
      "train Loss: 0.0845 Acc: 0.9701\n",
      "Time elapsed 31m 15s\n",
      "valid Loss: 0.0777 Acc: 0.9741\n",
      "Optimizer learning rate : 0.0001250\n",
      "\n",
      "Epoch 23/29\n",
      "----------\n",
      "Time elapsed 32m 27s\n",
      "train Loss: 0.0849 Acc: 0.9695\n",
      "Time elapsed 32m 31s\n",
      "valid Loss: 0.0767 Acc: 0.9747\n",
      "Optimizer learning rate : 0.0001250\n",
      "\n",
      "Epoch 24/29\n",
      "----------\n",
      "Time elapsed 33m 44s\n",
      "train Loss: 0.0847 Acc: 0.9699\n",
      "Time elapsed 33m 48s\n",
      "valid Loss: 0.0762 Acc: 0.9748\n",
      "Optimizer learning rate : 0.0001250\n",
      "\n",
      "Epoch 25/29\n",
      "----------\n",
      "Time elapsed 35m 2s\n",
      "train Loss: 0.0840 Acc: 0.9702\n",
      "Time elapsed 35m 5s\n",
      "valid Loss: 0.0744 Acc: 0.9756\n",
      "Optimizer learning rate : 0.0001250\n",
      "\n",
      "Epoch 26/29\n",
      "----------\n",
      "Time elapsed 36m 18s\n",
      "train Loss: 0.0838 Acc: 0.9693\n",
      "Time elapsed 36m 22s\n",
      "valid Loss: 0.0786 Acc: 0.9738\n",
      "Optimizer learning rate : 0.0001250\n",
      "\n",
      "Epoch 27/29\n",
      "----------\n",
      "Time elapsed 37m 35s\n",
      "train Loss: 0.0829 Acc: 0.9697\n",
      "Time elapsed 37m 39s\n",
      "valid Loss: 0.0776 Acc: 0.9735\n",
      "Optimizer learning rate : 0.0000625\n",
      "\n",
      "Epoch 28/29\n",
      "----------\n",
      "Time elapsed 38m 52s\n",
      "train Loss: 0.0822 Acc: 0.9706\n",
      "Time elapsed 38m 55s\n",
      "valid Loss: 0.0720 Acc: 0.9768\n",
      "Optimizer learning rate : 0.0000625\n",
      "\n",
      "Epoch 29/29\n",
      "----------\n",
      "Time elapsed 40m 9s\n",
      "train Loss: 0.0813 Acc: 0.9708\n",
      "Time elapsed 40m 13s\n",
      "valid Loss: 0.0781 Acc: 0.9744\n",
      "Optimizer learning rate : 0.0000625\n",
      "\n",
      "Training complete in 40m 13s\n",
      "Best val Acc: 0.976761\n"
     ]
    }
   ],
   "source": [
    "# user same strategy train again\n",
    "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.5)#学习率每7个epoch衰减成原来的1/10\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model_continue, val_acc_history, train_acc_history, valid_losses, train_losses, LRs  = train_model(model_continue, dataloaders, criterion, optimizer_ft, num_epochs=30, is_inception=False,filename=\"checkpoint_1_1.pth\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}